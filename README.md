# Web Scraping & Geocoding Platform

## Ã–zellikler
- ScrapingBee API ile seyahat destinasyon verisi Ã§ekme
- Herhangi bir .json dosyasÄ±nÄ± seÃ§ip iÅŸleyebilme (output.json, changed.json, vb.)
- Gemini AI ile otomatik etiketleme (Ã§Ä±ktÄ±: labeled_output.json)
- SeÃ§ilen dosya iÃ§in otomatik coÄŸrafi kodlama (geocoding_cli.py arka planda Ã§alÄ±ÅŸÄ±r)
- OpenStreetMap Ã¼zerinde tÃ¼m bulunan koordinatlarÄ± pop-up ile gÃ¶sterme
- Eksik kalan lokasyonlarÄ± harita altÄ±nda ayrÄ± listede gÃ¶sterme
- Åehir ve semt/ilÃ§e bilgisi kullanÄ±cÄ±dan alÄ±nabilir (varsayÄ±lan: Ä°stanbul/TÃ¼rkiye)
- Modern, kullanÄ±cÄ± dostu ve gerÃ§ek zamanlÄ± geri bildirimli Streamlit arayÃ¼zÃ¼
- API anahtarlarÄ± .env dosyasÄ±nda tutulur (gizli)
- KapsamlÄ± hata yÃ¶netimi ve veri doÄŸrulama

## KullanÄ±m
1. `requirements.txt` ile baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin.
2. `.env` dosyasÄ±na API anahtarÄ±nÄ±zÄ± ekleyin.
3. `streamlit run sbee_streamlit.py` ile uygulamayÄ± baÅŸlatÄ±n.
4. ArayÃ¼zden .json dosyasÄ± seÃ§in, etiketleme ve/veya coÄŸrafi kodlama iÅŸlemlerini baÅŸlatÄ±n.
5. SonuÃ§larÄ± harita ve listeler Ã¼zerinden inceleyin.

## Dosya AÃ§Ä±klamalarÄ±
- `sbee_streamlit.py`: Ana Streamlit uygulamasÄ±
- `geocoding_cli.py`: Komut satÄ±rÄ± coÄŸrafi kodlama aracÄ± (Streamlit arayÃ¼zÃ¼nden otomatik tetiklenir)
- `ScrapingBee/`: Scraping ve cache modÃ¼lleri
- `output.json`, `changed.json`, `labeled_output.json`: Veri dosyalarÄ±
- `requirements.txt`: Gerekli Python paketleri

## GÃ¼venlik ve Gizlilik
- API anahtarlarÄ± kodda yer almaz, .env dosyasÄ±nda tutulur.
- README ve kodda hassas bilgi bulunmaz.

## SÄ±k Sorulanlar
- Herhangi bir .json dosyasÄ± ile Ã§alÄ±ÅŸabilir miyim? **Evet.**
- CoÄŸrafi kodlama iÃ§in ÅŸehir/semt deÄŸiÅŸtirebilir miyim? **Evet, arayÃ¼zden girebilirsiniz.**
- Etiketleme Ã§Ä±ktÄ±sÄ± nereye kaydediliyor? **labeled_output.json**

```bash
# Clone the repository
git clone <repository-url>
cd web_scraping

# Install dependencies
pip install -r requirements.txt
```

### 2. Environment Setup

Create a `.env` file in the project root:

```env
# ScrapingBee API Configuration
SCRAPINGBEE_KEY=your_scrapingbee_api_key_here

# Gemini AI Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Geographic Coding APIs (Optional)
OPENCAGE_API_KEY=your_opencage_api_key_here
```

### 3. Run the Application

```bash
streamlit run sbee_streamlit.py
```

## ğŸ“‹ Usage Guide

### Step 1: Web Scraping
1. Enter a website URL in the input field
2. Click "ğŸš€ Fetch and Parse Data"
3. The system will extract travel destinations and save them to `output.json`

### Step 2: Destination Selection
1. Review the extracted destinations
2. Select destinations to remove (optional)
3. Click "ğŸ’¾ Save as changed.json" to save filtered data

### Step 3: AI Labeling
1. Click "ğŸ” Test Gemini API Connection" to verify API access
2. Click "ğŸ¤– Generate Labels with Gemini" to process destinations
3. View labeled results in the beautiful interface

### Step 4: Geographic Coding
1. Select any JSON file in the "EtiketlenmiÅŸ veriyle devam et" mode
2. Click "ğŸ“ KordinatlarÄ± bul, haritada gÃ¶ster" to run geocoding and display results
3. Found locations are shown on an interactive map with pop-ups (title, lat/lon)
4. Missing locations are listed below the map

## ğŸ“ Project Structure

```
web_scraping/
â”œâ”€â”€ sbee_streamlit.py          # Main Streamlit application
â”œâ”€â”€ geocoding_system.py        # Geographic coding system
â”œâ”€â”€ gemini_labeler.py          # Gemini AI labeling module
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # Environment variables (create this)
â”œâ”€â”€ output.json                # Original scraped data
â”œâ”€â”€ changed.json               # Filtered data for labeling
â”œâ”€â”€ labeled_output.json        # Final labeled data (user-named .json files also possible)
â”œâ”€â”€ ...                        # Other example or user-named labeled data
â”œâ”€â”€ cache/                     # HTML cache directory
â”œâ”€â”€ ScrapingBee/               # ScrapingBee package
â””â”€â”€ ...
```

## ğŸ”§ Configuration

### API Keys Required

1. **ScrapingBee API Key**: Get from [ScrapingBee](https://app.scrapingbee.com/)
2. **Gemini API Key**: Get from [Google AI Studio](https://aistudio.google.com/)
3. **OpenCage API Key** (Optional): Get from [OpenCage](https://opencagedata.com/) for enhanced geocoding
### Environment Variables

```env
SCRAPINGBEE_KEY=your_scrapingbee_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
OPENCAGE_API_KEY=your_opencage_api_key_here
```

## ğŸ¨ Features

### Modern UI Design
- Gradient backgrounds and animations
- Responsive card layouts
- Color-coded status indicators
- Interactive buttons with hover effects

### Smart Data Processing
- Automatic content extraction from HTML
- Intelligent text parsing and cleaning
- Efficient caching to reduce API calls
- Error handling and user feedback

### AI-Powered Labeling
- Context-aware label selection (up to 3 labels per destination)
- Fallback mechanisms for API errors

### Geographic Coding System
- 4-stage progressive geocoding approach
- OpenStreetMap integration via Nominatim
- Enhanced queries with fuzzy matching
- Optional API integrations (OpenCage, LocationIQ)
- Interactive map visualization with pop-ups
- Progress tracking and result management

## ğŸ“Š Output Format

### Input (`changed.json`)
```json
[
  {
    "title": "Destination Name",
    "content": "Description of the destination..."
  }
]
```

### Output (`labeled_output.json`)
```json
[
  {
    "title": "Destination Name",
    "content": "Description of the destination...",
    "labels": ["Plaj", "Aile Dostu", "Ekonomik"]
  }
]
```

## ğŸ› ï¸ Development

### Adding New Labels

You can customize label logic in `gemini_labeler.py` if needed.

### Customizing the UI

Modify the CSS in `sbee_streamlit.py` to change colors, fonts, and layouts.

## ğŸ” Troubleshooting

### Common Issues

1. **API Connection Failed**
   - Check your API keys in `.env` file
   - Verify API quotas and billing
   - Test connection using the built-in test button

2. **No Data Extracted**
   - Check if the URL is accessible
   - Verify the website structure
   - Try different URLs

3. **Labels Not Generated**
   - Ensure Gemini API is working
   - Check API quotas
   - Verify the `changed.json` file exists

## ğŸ“ˆ Performance Tips

- Use caching to minimize API calls
- Process data in batches for large datasets
- Monitor API quotas to avoid rate limits
- Test with small datasets first

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [ScrapingBee](https://scrapingbee.com/) for web scraping API
- [Google Gemini](https://ai.google.dev/) for AI labeling
- [Streamlit](https://streamlit.io/) for the web interface
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) for HTML parsing 

## ğŸ†• Version History

### [Yeni SÃ¼rÃ¼m] - GÃ¼ncel DeÄŸiÅŸiklikler
- Herhangi bir .json dosyasÄ±ndan otomatik koordinat bulma ve haritada gÃ¶sterme Ã¶zelliÄŸi eklendi
- "KordinatlarÄ± bul, haritada gÃ¶ster" butonu ile seÃ§ilen dosya Ã¼zerinden geocoding_cli.py otomatik Ã§alÄ±ÅŸÄ±r
- Bulunan lokasyonlar OpenStreetMap Ã¼zerinde pop-up'lÄ± olarak gÃ¶sterilir
- Bulunamayan lokasyonlar ayrÄ± bir bilgi kutusunda listelenir
- Åehir ve Ã¼lke inputlarÄ± kaldÄ±rÄ±ldÄ±, otomatik olarak Ä°stanbul/TÃ¼rkiye kullanÄ±lÄ±r
- Modern hata yÃ¶netimi ve kullanÄ±cÄ±ya anlÄ±k bilgilendirme eklendi
- KullanÄ±cÄ± deneyimi ve arayÃ¼z akÄ±ÅŸÄ± sadeleÅŸtirildi 
